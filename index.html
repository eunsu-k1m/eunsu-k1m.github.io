<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Eunsu Kim</title>

    <meta name="author" content="Jon Barron">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="img/favicon/favicon-16x16.png">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Eunsu Kim
                </p>
                <!-- Add Audio Player Next to the Name -->
<!--                 <audio id="namePronunciation" style="vertical-align: middle;" controls>
                  <source src="https://eunsu-k1m.github.io/eunsu_voice.mp3 type="audio/mpeg">
                </audio> -->
                <p class="bigger">
                  <br>
                                I am a visiting scholar at <a href="https://www.cmu.edu/">Carnegie Mellon University</a>, working with Professor <a href="https://www.cs.cmu.edu/~sherryw/">Sherry Tongshuang Wu</a>. I am also a master's student advised by Professor <a href="https://aliceoh9.github.io/">Alice Oh</a> at the <a href="https://cs.kaist.ac.kr/" class="bigger">School of Computing, KAIST</a>.
                      <br><br>
                      My research aims to develop AI systems and agents that serve as meaningful bridges: connecting individuals, societies, and humans with intelligent agents.
                      <br>
                      Currently, I've been focusing on two questions:
                      (1) How effectively can large language models (LLMs) assist humans in real-world contexts?
                      (2) How well do they understand and represent diverse multicultural and multilingual societies?
                      <br><br>
                      My ongoing projects explore human-AI collaboration and the evaluation of VLLMs‚Äô social and cultural capabilities.
                    <!-- (i) What to evaluate: Exploring the direction in which LLMs should progress and examining current LLM behavior from that perspective <a href="#3">[3,</a> <a href="#4">4]</a>. (ii) How to evaluate: Developing evaluation frameworks/metrics that measure the true capabilities of LLMs <a href="#2">[2,</a> <a href="#5">5]</a>. (iii) Interesting behaviors during evaluation: Digging into the behaviors observed in (1)&(2) <a href="#1">[1,</a><a href="#5">5]</a>. <br>
                    I believe accurate evaluation in the proper context can guide LLMs to develop in meaningful and appropriate directions.

                    <br><br> -->
                    <!-- Currently, I'm working on developing an LLM evaluation framework that is reliable and interpretable, and benchmarking cultural awareness of (V)LM in various interesting scenarios. -->
 
                    If you would like to collaborate with me or have any questions, Feel free to contact me!
                </p>

                
                <div style="text-align: center;">
                    <a href="kes0317@kaist.ac.kr">Email</a> &nbsp;/&nbsp;
                    <!-- <a href="data/JonBarron-CV.pdf">CV</a> &nbsp;/&nbsp;
                    <a href="data/JonBarron-bio.txt">Bio</a> &nbsp;/&nbsp; -->
                    <a href="https://scholar.google.com/citations?user=eoL3C_MAAAAJ&hl=ko">Scholar</a> &nbsp;/&nbsp;
                    <a href="https://www.linkedin.com/in/euns0o-kim/">LinkedIn</a> &nbsp;/&nbsp;
                    <a href="https://x.com/euns0o_kim">Twitter(X)</a> &nbsp;/&nbsp;
                    <a href="https://eunsu-k1m.github.io/CV_0928.pdf">CV</a>
                    <!-- <a href="https://github.com/jonbarron/">Github</a> -->
                </div>

              </td>
              <td style="padding:2.5%;width:40%;max-width:40%">
                <div  class="image-container">
                <img src="img/photo.jpg" alt="profile photo" class=default-img"></a>
                <img src="img/photo2.jpg" alt="hover profile photo" class="hover-img">
              </td>
              <div class="hover-text" style="position: absolute; top: 50%; left: 50%; transform: translate(-50%, -50%); color: white; font-size: 20px; display: none;">
                My happiest moment so far!
              

              </div>
            </tr>
          </tbody></table>
          <tr>
          <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Affiliations</h2>
            
                <div class="education-entry">
                  <h3>Carnegie Mellon University (CMU)</h3>
                  <p>
                    <span class="container">
                      <em class="left">Visiting Scholar in HCII Computer Science, Host professor: Sherry Wu</em>
                      <span class="right">2025.09-present</span>
                    </span>
                  </p>
                </div>
            
                <div class="education-entry">
                  <h3>Korea Advanced Institute of Science and Technology (KAIST)</h3>
                  <p>
                    <span class="container">
                      <em class="left">M.S. in Computer Science, Advisor: Alice Oh</em>
                      <span class="right">2023.09-present</span>
                    </span>
                  </p>
                  <p>
                    <span class="container">
                      <em class="left">B.S. in Electrical Engineering</em>
                      <span class="right">2019.03‚Äì2023.08</span>
                    </span>
                    <span class="smallicon">&#9679;</span>
                    <em><strong>GPA: 4.02/4.3, Major GPA: 4.15/4.3 (Summa Cum Laude)</strong></em>
                  </p>
                </div>
              </td>
            </tr>
            
            <!-- Latest News Section -->
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>Latest News!</h2>
            
                <div class="news-entry">
                  <p>
                    <span class="container">
                      <em class="left">üá∫üá∏ Starting as a visiting student at Carnegie Mellon University (CMU)!</em>
                      <span class="right">Sep 2025</span>
                    </span>
                  </p>
                </div>
            
                <div class="news-entry">
                  <p>
                    <span class="container">
                      <em class="left">üèÜ Two papers accepted to EMNLP 2025 Findings!<br>
                      <strong>Uncovering Factor Level Preferences to Improve Human-Model Alignment</strong> | <strong>MUG-Eval</strong></em>                                                                                             
                      <span class="right">Aug 2025</span>
                    </span>
                  </p>
                </div>
            
                <div class="news-entry">
                  <p>
                    <span class="container">
                      <em class="left">üèÜ Three papers accepted to ACL 2025 ‚Äî two in Findings and one as Main (Oral)!<br>
                      <strong>LLM-as-an-Interviewer</strong> | <strong>Spotting Out-of-Character Behavior</strong> | <strong>Diffusion Models Through a Global Lens</strong></em>
                      <span class="right">May 2025</span>
                    </span>
                  </p>
                </div>
                <div class="news-entry">
                  <p>
                    <span class="container">
                      <em class="left">üèÜ `When Tom Eats Kimchi' paper got outstanding paper awards in NAACL C3NLP! Congrats to my interns!<br>                                                                                                
                      <span class="right">Mar 2025</span>
                    </span>
                  </p>
                </div>
              </td>
            </tr>

            
            <tr>
              <td style="padding:20px;width:100%;vertical-align:middle">
                <h2>
  Selected Publications 
  (<a href="https://scholar.google.com/citations?user=eoL3C_MAAAAJ&hl=en" style="font-size: inherit; color: inherit; text-decoration: none;">See All</a>)
</h2>
                <h3>* denotes equal contributions</h3>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;max-width:850px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                 <!--   cultural-mix  -->
        <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
            <td style="padding:5px 20px 10px 40px; width:100%; vertical-align:middle;">
                <strong>
                    <span class="papertitle"><li id="1">BenchHub: A Unified Benchmark Suite for Holistic and Customizable LLM Evaluation</span>
                </strong>
                <br>
                <strong><u>Eunsu Kim</u>*</strong>, Haneul Yoo*, Guijin Son, Hitesh Patel, Amit Agarwal, Alice Oh
                <br>
                <em>Preprint, Under Review</em>
                <br> 
                <a href="https://arxiv.org/abs/2506.00482">paper</a>
              
            </td>
        </tr>
                 <!--   cultural-mix  -->
        <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
            <td style="padding:10px 20px 10px 40px; width:100%; vertical-align:middle;">

                <strong>
                    <span class="papertitle"><li id="1">MUG-Eval: A Proxy Evaluation Framework for Multilingual Generation Capabilities in Any Language</span>
                </strong>
                <br>
                Seyoung Song*, Seogyeong Jeong*, <strong><u>Eunsu Kim</u></strong>, Jiho Jin, Dongkwan Kim, Jay Shin, Alice Oh
                <br>
                <em>EMNLP 2025(Findings)</em>
                <br> 
                <a href="https://arxiv.org/abs/2505.14395">paper</a>
              
            </td>
        </tr>

            <!--   diffusion  -->
        <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
            <td style="padding:10px 20px 10px 40px; width:100%; vertical-align:middle;">

                <strong>
                    <span class="papertitle"><li id="1">Diffusion Models Through a Global Lens: Are They Culturally Inclusive?</span>
                </strong>
                <br>
                Zahra Bayramli*, Ayhan Suleymanzade*, Na Min An, Huzama Ahmad, <strong><u>Eunsu Kim</u></strong>, Junyeong Park, James Thorne, Alice Oh
                <br>
                <em>ACL 2025 (Oral), NAACL 2025 c3NLP workshop</em>
                <br>
                <a href="https://arxiv.org/abs/2502.08914">arXiv</a>
                <a onclick="toggleText('hidden-text-diffusion')">TL;DR</a>
                <p id="hidden-text-diffusion" class="hidden-text">
                    Text-to-image diffusion models have recently enabled the creation of visually compelling, detailed images from textual prompts. However, their ability to accurately represent various cultural nuances remains an open question. In our work, we introduce CultDiff benchmark, evaluating state-of-the-art diffusion models whether they can generate culturally specific images spanning ten countries. We show that these models often fail to generate cultural artifacts in architecture, clothing, and food, especially for underrepresented country regions, by conducting a fine-grained analysis of different similarity aspects, revealing significant disparities in cultural relevance, description fidelity, and realism compared to real-world reference images. With the collected human evaluations, we develop a neural-based image-image similarity metric, namely, CultDiff-S, to predict human judgment on real and generated images with cultural artifacts. Our work highlights the need for more inclusive generative AI systems and equitable dataset representation over a wide range of cultures.
                </p>
            </td>
        </tr>
            
          <!--   interviewer  -->
        <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
            <td style="padding:10px 20px 10px 40px; width:100%; vertical-align:middle;">

                <strong>
                    <span class="papertitle"><li id="1">LLM-AS-AN-INTERVIEWER: Beyond Static Testing Through Dynamic LLM Evaluation</span>
                </strong>
                <br>
                <strong><u>Eunsu Kim</u></strong>, Juyoung Suk, Seungone Kim, Niklas Muennighoff, Dongkwan Kim, Alice Oh
                <br>
                <em>ACL 2025 Findings</em>
                <br>
                <a href="https://arxiv.org/abs/2412.10424">arXiv</a>
                <a href="https://github.com/interview-eval/interview-eval/tree/main">codebase</a>
                <a onclick="toggleText('hidden-text-interview')">TL;DR</a>
                <p id="hidden-text-interview" class="hidden-text">
                    LLM-as-an-Interviewer is an evaluation framework that assesses the capabilities of LLMs through an interview-style process. In this approach, the LLM acting as the interviewer evaluates other LLMs by providing feedback and asking follow-up questions, enabling a more comprehensive assessment of their capabilities.

                </p>
            </td>
        </tr>
             <!--   /ICLR 2025: PROFILE  -->
            <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
              <td style="padding:10px 20px 10px 40px; width:100%; vertical-align:middle;">
              <strong>
                <span class="papertitle"><li id="5">Uncovering Factor Level Preferences to Improve Human-Model Alignment</span>
              </strong>
              <br>
              Juhyun Oh*, <strong><u>Eunsu Kim*</u></strong>, Jiseon Kim, Wenda Xu, William Yang Wang, Alice Oh
              <br>
              <em>EMNLP 2025 (Findings)
              <br>
              <a href="https://arxiv.org/pdf/2410.06965">arXiv</a>
                            <br>
              </td>
          </tr>
          <!--    /ICLR 2025: PROFILE   -->                
            
          <!--   /NIPS 2024: BLEND  -->
          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
              <td style="padding:10px 20px 10px 40px; width:100%; vertical-align:middle;">
              <strong>
                <span class="papertitle"><li id="4">BLEnD: A Benchmark for LLMs on Everyday Knowledge in Diverse Cultures and Languages</span>
              </strong>
              <br>
          Junho Myung, Nayeon Lee, Yi Zhou, Jiho Jin, Rifki Afina Putri, Dimosthenis Antypas, Hsuvas Borkakoty,<strong><u>Eunsu Kim</u></strong>, Carla Perez-Almendros, Abinew Ali Ayele, V√≠ctor Guti√©rrez-Basulto, Yazm√≠n Ib√°√±ez-Garc√≠a, Hwaran Lee, Shamsuddeen Hassan Muhammad, Kiwoong Park, Anar Sabuhi Rzayev, Nina White, Seid Muhie Yimam, Mohammad Taher Pilehvar, Nedjma Ousidhoum, Jose Camacho-Collados, Alice Oh
              <br>
              <em>Neurips D&B, 2025
              <br>
              <a href="https://arxiv.org/abs/2406.09948">arXiv</a>
              <a href="https://huggingface.co/datasets/nayeon212/BLEnD">Dataset</a>
              <a onclick="toggleText('hidden-text-blend')">TL;DR</a>
              <p id="hidden-text-blend" class="hidden-text">
              Large language models (LLMs) often lack culture-specific knowledge of daily life, especially across diverse regions and non-English languages. Existing benchmarks for evaluating LLMs' cultural sensitivities are limited to a single language or collected from online sources such as Wikipedia, which do not reflect the mundane everyday lifestyles of diverse regions. That is, information about the food people eat for their birthday celebrations, spices they typically use, musical instruments youngsters play, or the sports they practice in school is common cultural knowledge but uncommon in easily collected online sources, especially for underrepresented cultures. To address this issue, we introduce BLEnD, a hand-crafted benchmark designed to evaluate LLMs' everyday knowledge across diverse cultures and languages. BLEnD comprises 52.6k question-answer pairs from 16 countries/regions, in 13 different languages, including low-resource ones such as Amharic, Assamese, Azerbaijani, Hausa, and Sundanese. We construct the benchmark to include two formats of questions: short-answer and multiple-choice. We show that LLMs perform better for cultures that are highly represented online, with a maximum 57.34% difference in GPT-4, the best-performing model, in the short-answer format. For cultures represented by mid-to-high-resource languages, LLMs perform better in their local languages, but for cultures represented by low-resource languages, LLMs perform better in English than the local languages.               </p>
            </td>
          </tr>
          <!--   /NIPS 2024: BLEND  -->    


          <!--   /LREC-COLING 2024: CLIcK  -->
          <tr onmouseout="smerf_stop()" onmouseover="smerf_start()">
              <td style="padding:10px 20px 10px 40px; width:100%; vertical-align:middle;">
              <strong>
                <span class="papertitle"><li id="3">CLIcK: Evaluation of Cultural and Linguistic Intelligence in Korean</span>
              </strong>
              <br>
          <strong><u>Eunsu Kim</u></strong>,
          Juyoung Suk, Philhoon Oh, Haneul Yoo, James Thorne, Alice Oh
              <br>
              <em>LREC-COLING 2024
              <br>
              <a href="https://arxiv.org/abs/2403.06412">arXiv</a>
              <a href="https://github.com/rladmstn1714/CLIcK">Dataset</a>
              <a onclick="toggleText('hidden-text-click')">TL;DR</a>
              <p id="hidden-text-click" class="hidden-text">
               <img src='img/CLICK.png' width=30%><br>
              We construct and release CLIcK, a culturally-aware evaluation benchmark dataset encompassing 1,995 instances across 11 categories representing facets of the Korean culture, ranging from everyday life to specific subject areas, as well as Korean grammar and linguistics.
              </p>
            </td>
          </tr>
          <!--   /LREC-COLING 2024: CLIcK  -->      
       

          <!--   /EACL 2024 : paradox  -->
        
        <!-- Ïù¥Ï†Ñ ÏÑπÏÖò ÎßàÎ¨¥Î¶¨ -->
        </tbody></table>
        
        <!-- Misc ÏÑπÏÖò (ÏÉà ÌÖåÏù¥Î∏îÎ°ú Í∞êÏã∏Í∏∞) -->
        <table style="width:100%;max-width:850px;border:0;border-spacing:0;border-collapse:separate;margin:0 auto;">
          <tbody>
            <tr>
              <td style="padding:20px 20px 20px 40px; width:100%; vertical-align:middle;">
                <h2>Misc</h2>
        
                <!-- Î¨∏Îã® Í∏∞Î≥∏ ÎßàÏßÑÏù¥ Ïª§ Î≥¥Ïù¥Î©¥ marginÏùÑ Ï§ÑÏó¨Ï£ºÏÑ∏Ïöî -->
                <p class="bigger" style="margin:8px 0 0 0;">
                  Besides research, I love bread ü•Øü•êü•®, table tennis üèì, and learning new sports. I recently started tennis and yoga!
                </p>
        
                <table style="width:100%;border:0;border-spacing:0;border-collapse:separate;margin-right:auto;margin-left:auto;">
                  <tbody>
                    <tr>
                      <td style="padding:0">
                        <p style="text-align:right;font-size:small;margin:16px 0 0 0;">
                          Template from <a href="https://jonbarron.info/">Jon Barron's</a> wonderful work.
                        </p>
                      </td>
                    </tr>
                  </tbody>
                </table>
        
              </td>
            </tr>
          </tbody>
        </table>

      <script>
          function toggleText(id) {
              const textElement = document.getElementById(id);
              if (textElement.style.display === 'none' || textElement.style.display === '') {
                  textElement.style.display = 'block';
              } else {
                  textElement.style.display = 'none';
              }
          }
      </script>
  </body>
</html>
